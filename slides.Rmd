---
title: "King Edwards VII BTEC Applied Science visit"
author: "Mark Dunning - The University of Sheffield"
output:
  slidy_presentation: default
  ioslides_presentation: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
 
# Introduction to Bioinformatics

## Definition

> an interdisciplinary field that develops methods and software tools for understanding biological data, in particular when the data sets are large and complex

## Other related applications

<img src="images/job-trends.png"style="width: 100%; display: block; margin-left: auto; margin-right: auto;"/>


## Data Explosion

![](images/seq-growth.png)


## Genetic Code

- Every cell in our body contains DNA code
- The code is written using the "letters" A, T, C, G

![](images/genetic-code.PNG)


## A blueprint for life (an analogy)

- Imagine we are trying to construct a piece of furniture
- We are often given a set of instructions to follow

![](images/blueprint.PNG)

## A blueprint for life (an analogy)

- Good, clear error-free instructions will give us the results we want

![](images/blueprint-2.PNG)

## A blueprint for life (an analogy)

- But errors in the instructions will produce a different result to expected
- Some errors are more serious than others

![](images/blueprint-3.PNG)

## Back to the the human genome

- The code for a human is more like an entire bookcase
- Errors can occur on any page, in any book, on any shelf

![](images/genome-size.PNG)

## Why use computers

- Nobody has the time and patience to search all these pages for errors
- Computers never get bored, or need a rest
- Computers are good at repetitive tasks and following instructions
- However, computers still need humans to give them instructions (program)
  + and to fix them when errors occur
  + and to interpret the results

![](images/genome-size.PNG)

## Demo time!

# Data Management
 
## Context

![](images/metabric.png)
 
## Context 
 
- What the wet-lab scientists wanted us to spend time looking at

<img src="images/metabric-clusters.png" style="width: 80%; display: block; margin-left: auto; margin-right: auto;"/>

## Context

- What we *actually* spent time looking at (Disclaimer: not actual data from this project)

<img src="images/oh-the-horror.png" style="width: 100%; display: block; margin-left: auto; margin-right: auto;"/>

## Context

No matter how much of the analysis is automated, some manual steps are inevitably involved

<img src="images/metadata.png" style="width: 75%; display: block; margin-left: auto; margin-right: auto;"/>


## Reproducible Research

- An analysis needs to be *automated* to be properly reproducible
- Tools like R, Python, will help with this but the data needs to be formatted correctly in the first place
    + R, Python cannot magically read any type of file you give them
- **Making spreadsheets tidy at the start of the analysis will save a lot of time in the long-run**



## Should we stop using Excel completely?

- ....Not neccesarily.
- Often much more convenient to eye-ball a spreadsheet and get an overall impression of your data. 
- But they have *limitations* making them not ideal for large-scale analyses. 
- Doing things by-hand only invites you to make copy-and-paste errors etc



    
## Short Exercise

- Imagine you have been asked to fill out the following spreadsheet for a clinical study involving smokers or non-smokers
- What words, letters, etc would you put in the second column to indicate if the patient was a smoker or not?

![](images/smoker.PNG)

## Rule 1

![](images/female.png)



## Rule 1 - ***Maintain consistency***



## Example 1

| Patient ID | Sex    | Date of Diagnosis     | Tumour Size
|------------|--------|-------------------|------------
| 1          | M      | 01-01-2013        |     3.1
| 2          | f      | 04-18-1998        |     1.5
| 3          | Male   | 1st of April 2004 |     105
| 4          | Female | NA                |     67
| 5          | F      | 2010/03/12        |     4.2
| 6          | F      |                   |     3.6
| 7          | M      | 1994-11-05T08:15:30-05:00         |     232



## Example 1

- Consistency: F, female, f, fem, 2, …
- Units
    + cm or mm; days, months or years
- You can introduce inconsistencies without realising it
    + blank spaces (whitespace) at the end of text
    + "Male " is not the same as "Male"
- Document choices you make about units in a *README* file



## Regarding dates

credit: @myusuf3

![](images/dates.jpg)



## Example 1 - corrected

| Patient ID | Sex  | Date of Diagnosis | Tumour Size
|------------|------|---------------|------------
| 001          | M    | 2013-01-01    |   3.1 
| 002          | F    | 1998-04-18    |   1.5
| 003          | M    | 2004-04-01    |   1.05
| 004          | F    | NA            |   0.67
| 005          | F    | 2010-03-12    |   4.2
| 006          | F    | NA            |   3.6
| 007          | M    | 1994-11-05   |   2.32


## Rule 2

![](https://news.artnet.com/app/news-upload/2014/04/Ecce-Homo.jpg)

## Rule 2 - ***Never work directly on the raw data***



## Rule 2

- ***Never work directly on the raw data***
- Hard to reverse all the manual steps performed and invites errors
- Store the original data somewhere safe
    + see later

## Rule 3

Figure showing locations of visitors to my Prostate Cancer [data portal](http://bioinformatics.cruk.cam.ac.uk/apps/camcAPP/)

![](images/zeros-are-data.png)



## Rule 3 - Don't use 0 to mean missing

- Zero values are data!
    + Sometimes extreme values such as 999 are sometimes used
- `NA` is Ok, but what if NA is a valid category in your data?
    + R will recognise `NA` as a missing value and can ignore it in calculations
- Safest to leave the cell *empty*
    + but you need to be careful with blank spaces



## Rule 4

| Patient ID | Date       | Value |
|------------|------------|-------|
| 1          | 2015-06-14 | 213   |
| 2          |            | 76.5  |
| 3          | 2015-06-18 | 32    |
| 4          |            | 120.3 |
| 5          |            | 109   |
| 6          | 2015-06-20 |       |
| 7          |            | 143   |




## Rule 4 

 Fill in all the cells



## Rule 4

- It is tempting to make the table look cleaner by not repeating some values
- Fill in all cells!
    + otherwise, problems when sorting
- Empty cell:
    + missing value?
    + value meant to be repeated multiple times?
- Make sure it’s clear that the data is missing and not unintentionally left blank



## Example 2 Corrected

| Patient ID | Date       | Value |
|------------|------------|-------|
| 1          | 2015-06-14 | 213   |
| 2          | 2015-06-14 | 76.5  |
| 3          | 2015-06-18 | 32    |
| 4          | 2015-06-18 | 120.3 |
| 5          | 2015-06-18 | 109   |
| 6          | 2015-06-20 | NA    |
| 7          | 2015-06-20 | 143   |




## Rule 5

![](images/irregular.png)



## Rule 5

Make it rectangle

- The computer expects a very rigid shape of data with rows and columns
- Each column is a *variable* being examined
- Each row is an observation
- A concept commonly known as [*tidy data*](http://vita.had.co.nz/papers/tidy-data.pdf)



## Rule 5

![](images/regular.png)



## More

- Don’t put too much information in one cell
    + 1 cell = 1 piece of information
- Don’t include units such as "30 g" → "g" in the column name
    + http://unitsofmeasure.org/ucum.html 
- Write notes in a separate column or data dictionary or metadata 
    + "0 (below threshold)"
    


## More

- NO calculations
- NO font colours
- NO highlighting

Computer doesn’t recognize it!

## Demo time

- Download the file `patient-data.xlsx` and open in Excel, or equivalent software
  + you may need to right-click on the link and choose Save link as.. (or similar)
- This is a *simulated*, but representative, example of **bad data**
- Discuss with your neighbours what aspects of the dataset would make it difficult for a computer to process (around 5 minutes)
